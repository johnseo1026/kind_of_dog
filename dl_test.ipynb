{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow.keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/dev/dog-breed-identification/train'\n",
    "test_dir = 'C:/dev/dog-breed-identification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10222, 10357)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = len(os.listdir('C:/dev/dog-breed-identification/train'))\n",
    "test_size = len(os.listdir('C:/dev/dog-breed-identification/test'))\n",
    "\n",
    "train_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/dev/dog-breed-identification/labels.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['affenpinscher',\n",
       " 'afghan_hound',\n",
       " 'african_hunting_dog',\n",
       " 'airedale',\n",
       " 'american_staffordshire_terrier',\n",
       " 'appenzeller',\n",
       " 'australian_terrier',\n",
       " 'basenji',\n",
       " 'basset',\n",
       " 'beagle',\n",
       " 'bedlington_terrier',\n",
       " 'bernese_mountain_dog',\n",
       " 'black-and-tan_coonhound',\n",
       " 'blenheim_spaniel',\n",
       " 'bloodhound',\n",
       " 'bluetick',\n",
       " 'border_collie',\n",
       " 'border_terrier',\n",
       " 'borzoi',\n",
       " 'boston_bull',\n",
       " 'bouvier_des_flandres',\n",
       " 'boxer',\n",
       " 'brabancon_griffon',\n",
       " 'briard',\n",
       " 'brittany_spaniel',\n",
       " 'bull_mastiff',\n",
       " 'cairn',\n",
       " 'cardigan',\n",
       " 'chesapeake_bay_retriever',\n",
       " 'chihuahua',\n",
       " 'chow',\n",
       " 'clumber',\n",
       " 'cocker_spaniel',\n",
       " 'collie',\n",
       " 'curly-coated_retriever',\n",
       " 'dandie_dinmont',\n",
       " 'dhole',\n",
       " 'dingo',\n",
       " 'doberman',\n",
       " 'english_foxhound',\n",
       " 'english_setter',\n",
       " 'english_springer',\n",
       " 'entlebucher',\n",
       " 'eskimo_dog',\n",
       " 'flat-coated_retriever',\n",
       " 'french_bulldog',\n",
       " 'german_shepherd',\n",
       " 'german_short-haired_pointer',\n",
       " 'giant_schnauzer',\n",
       " 'golden_retriever',\n",
       " 'gordon_setter',\n",
       " 'great_dane',\n",
       " 'great_pyrenees',\n",
       " 'greater_swiss_mountain_dog',\n",
       " 'groenendael',\n",
       " 'ibizan_hound',\n",
       " 'irish_setter',\n",
       " 'irish_terrier',\n",
       " 'irish_water_spaniel',\n",
       " 'irish_wolfhound',\n",
       " 'italian_greyhound',\n",
       " 'japanese_spaniel',\n",
       " 'keeshond',\n",
       " 'kelpie',\n",
       " 'kerry_blue_terrier',\n",
       " 'komondor',\n",
       " 'kuvasz',\n",
       " 'labrador_retriever',\n",
       " 'lakeland_terrier',\n",
       " 'leonberg',\n",
       " 'lhasa',\n",
       " 'malamute',\n",
       " 'malinois',\n",
       " 'maltese_dog',\n",
       " 'mexican_hairless',\n",
       " 'miniature_pinscher',\n",
       " 'miniature_poodle',\n",
       " 'miniature_schnauzer',\n",
       " 'newfoundland',\n",
       " 'norfolk_terrier',\n",
       " 'norwegian_elkhound',\n",
       " 'norwich_terrier',\n",
       " 'old_english_sheepdog',\n",
       " 'otterhound',\n",
       " 'papillon',\n",
       " 'pekinese',\n",
       " 'pembroke',\n",
       " 'pomeranian',\n",
       " 'pug',\n",
       " 'redbone',\n",
       " 'rhodesian_ridgeback',\n",
       " 'rottweiler',\n",
       " 'saint_bernard',\n",
       " 'saluki',\n",
       " 'samoyed',\n",
       " 'schipperke',\n",
       " 'scotch_terrier',\n",
       " 'scottish_deerhound',\n",
       " 'sealyham_terrier',\n",
       " 'shetland_sheepdog',\n",
       " 'shih-tzu',\n",
       " 'siberian_husky',\n",
       " 'silky_terrier',\n",
       " 'soft-coated_wheaten_terrier',\n",
       " 'staffordshire_bullterrier',\n",
       " 'standard_poodle',\n",
       " 'standard_schnauzer',\n",
       " 'sussex_spaniel',\n",
       " 'tibetan_mastiff',\n",
       " 'tibetan_terrier',\n",
       " 'toy_poodle',\n",
       " 'toy_terrier',\n",
       " 'vizsla',\n",
       " 'walker_hound',\n",
       " 'weimaraner',\n",
       " 'welsh_springer_spaniel',\n",
       " 'west_highland_white_terrier',\n",
       " 'whippet',\n",
       " 'wire-haired_fox_terrier',\n",
       " 'yorkshire_terrier']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting different classes\n",
    "dog_breeds = sorted(df['breed'].unique())\n",
    "n_classes = len(dog_breeds)\n",
    "print(n_classes)\n",
    "dog_breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting classes to numbers\n",
    "class_to_num = dict(zip(dog_breeds,range(n_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Function to load and convert images to array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def images_to_array(data_dir,df,image_size):\n",
    "    image_names = df['id']\n",
    "    image_labels = df['breed']\n",
    "    data_size = len(image_names)\n",
    "    \n",
    "    X = np.zeros([data_size,image_size[0],image_size[1],image_size[2]],dtype = np.uint8)\n",
    "    y = np.zeros([data_size,1],dtype = np.uint8)\n",
    "    \n",
    "    for i in range(data_size):\n",
    "        img_name = image_names[i]\n",
    "        img_dir = os.path.join(data_dir,img_name+'.jpg')\n",
    "        img_pixels = load_img(img_dir,target_size=image_size)\n",
    "        X[i] = img_pixels\n",
    "        y[i] = class_to_num[image_labels[i]]\n",
    "        \n",
    "    y = to_categorical(y)\n",
    "    \n",
    "    ind = np.random.permutation(data_size)\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    print('Ouptut Data Size: ', X.shape)\n",
    "    print('Ouptut Label Size: ', y.shape)\n",
    "    return X, y     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting image size according to pretrained models\n",
    "img_size = (299,299,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouptut Data Size:  (10222, 299, 299, 3)\n",
      "Ouptut Label Size:  (10222, 120)\n"
     ]
    }
   ],
   "source": [
    "X, y = images_to_array(train_dir,df,img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract features from images\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D,Lambda, Dropout, InputLayer, Input\n",
    "\n",
    "def get_features(model_name, data_preprocessor, input_size, data):\n",
    "    #Prepare pipeline.\n",
    "    input_layer = Input(input_size)\n",
    "    preprocessor = Lambda(data_preprocessor)(input_layer)\n",
    "    base_model = model_name(weights='imagenet', include_top=False,\n",
    "                            input_shape=input_size)(preprocessor)\n",
    "    avg = GlobalAveragePooling2D()(base_model)\n",
    "    feature_extractor = Model(inputs = input_layer, outputs = avg)\n",
    "    #Extract feature.\n",
    "    feature_maps = feature_extractor.predict(data, batch_size=32, verbose=1)\n",
    "    print('Feature maps shape: ', feature_maps.shape)\n",
    "    return feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Owner\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "10222/10222 [==============================] - 1419s 139ms/sample\n",
      "Feature maps shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "#Extracting features using InceptionV3\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "inception_preprocessor = preprocess_input\n",
    "inception_features = get_features(InceptionV3,\n",
    "                                  inception_preprocessor,\n",
    "                                  img_size,\n",
    "                                  X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 2708s 265ms/sample\n",
      "Feature maps shape:  (10222, 2048)\n"
     ]
    }
   ],
   "source": [
    "#Extracting features using Xception\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "xception_preprocessor = preprocess_input\n",
    "xception_features = get_features(Xception,\n",
    "                                 xception_preprocessor,\n",
    "                                 img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10222/10222 [==============================] - 3359s 329ms/sample\n",
      "Feature maps shape:  (10222, 1536)\n"
     ]
    }
   ],
   "source": [
    "#Extracting features using InceptionResnetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "inc_resnet_preprocessor = preprocess_input\n",
    "inc_resnet_features = get_features(InceptionResNetV2,\n",
    "                                   inc_resnet_preprocessor,\n",
    "                                   img_size, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature maps shape (10222, 5632)\n"
     ]
    }
   ],
   "source": [
    "#concatinating features\n",
    "final_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                 inc_resnet_features,], axis=-1)\n",
    "print('Final feature maps shape', final_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "EarlyStop_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "my_callback=[EarlyStop_callback]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "#Building Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(InputLayer(final_features.shape[1:]))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(120,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling Model\n",
    "model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9199 samples, validate on 1023 samples\n",
      "Epoch 1/50\n",
      "9199/9199 [==============================] - 7s 725us/sample - loss: 0.8512 - acc: 0.7993 - val_loss: 0.3509 - val_acc: 0.8876\n",
      "Epoch 2/50\n",
      "9199/9199 [==============================] - 4s 434us/sample - loss: 0.2634 - acc: 0.9160 - val_loss: 0.3647 - val_acc: 0.9013\n",
      "Epoch 3/50\n",
      "9199/9199 [==============================] - 4s 407us/sample - loss: 0.2119 - acc: 0.9327 - val_loss: 0.3885 - val_acc: 0.8974\n",
      "Epoch 4/50\n",
      "9199/9199 [==============================] - 4s 401us/sample - loss: 0.1796 - acc: 0.9389 - val_loss: 0.3800 - val_acc: 0.8974\n",
      "Epoch 5/50\n",
      "9199/9199 [==============================] - 4s 397us/sample - loss: 0.1472 - acc: 0.9497 - val_loss: 0.4323 - val_acc: 0.9032\n",
      "Epoch 6/50\n",
      "9199/9199 [==============================] - 4s 389us/sample - loss: 0.1341 - acc: 0.9553 - val_loss: 0.4177 - val_acc: 0.9013\n",
      "Epoch 7/50\n",
      "9199/9199 [==============================] - 4s 385us/sample - loss: 0.1209 - acc: 0.9572 - val_loss: 0.4407 - val_acc: 0.8964\n",
      "Epoch 8/50\n",
      "9199/9199 [==============================] - 3s 380us/sample - loss: 0.1046 - acc: 0.9620 - val_loss: 0.4201 - val_acc: 0.8974\n",
      "Epoch 9/50\n",
      "9199/9199 [==============================] - 3s 378us/sample - loss: 0.0984 - acc: 0.9634 - val_loss: 0.4302 - val_acc: 0.8983\n",
      "Epoch 10/50\n",
      "9199/9199 [==============================] - 4s 401us/sample - loss: 0.0975 - acc: 0.9646 - val_loss: 0.4693 - val_acc: 0.8964\n",
      "Epoch 11/50\n",
      "9199/9199 [==============================] - 6s 632us/sample - loss: 0.0793 - acc: 0.9712 - val_loss: 0.4435 - val_acc: 0.9071\n"
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "history = model.fit(final_features,\n",
    "                  y,\n",
    "                  batch_size=32,\n",
    "                  epochs=50,\n",
    "                  validation_split=0.1,\n",
    "                  callbacks=my_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting test images to array\n",
    "def images_to_array2(data_dir,df, img_size):\n",
    "    images_names = df['id']\n",
    "    data_size = len(images_names)\n",
    "    X = np.zeros([data_size, img_size[0], img_size[1], 3], dtype=np.uint8)\n",
    "    \n",
    "    for i in range(data_size):\n",
    "        image_name = images_names[i]\n",
    "        img_dir = os.path.join(data_dir, image_name+'.jpg')\n",
    "        img_pixels = load_img(img_dir, target_size=img_size)\n",
    "        X[i] = img_pixels\n",
    "        \n",
    "    print('Ouptut Data Size: ', X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('C:/dev/dog-breed-identification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouptut Data Size:  (10357, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "test_data = images_to_array2(test_dir, sample_df, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 1637s 158ms/sample\n",
      "Feature maps shape:  (10357, 2048)\n"
     ]
    }
   ],
   "source": [
    "#Extract test data features.\n",
    "inception_features = get_features(InceptionV3, inception_preprocessor, img_size, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10357/10357 [==============================] - 2889s 279ms/sample\n",
      "Feature maps shape:  (10357, 2048)\n"
     ]
    }
   ],
   "source": [
    "xception_features = get_features(Xception, xception_preprocessor, img_size, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3200/10357 [========>.....................] - ETA: 53:41"
     ]
    }
   ],
   "source": [
    "inc_resnet_features = get_features(InceptionResNetV2, inc_resnet_preprocessor, img_size, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = np.concatenate([inception_features,\n",
    "                                 xception_features,\n",
    "                                 inc_resnet_features],axis=-1)\n",
    "print('Final feature maps shape', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('dog_kind_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_features, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for breed in dog_breeds:\n",
    "    sample_df[breed] = y_pred[:,class_to_num[breed]]\n",
    "sample_df.to_csv('pred.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
