{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id             breed\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "label = pd.read_csv('C:/dev/dog-breed-identification/labels.csv')\n",
    "sample_submission = pd.read_csv\n",
    "('C:/dev/dog-breed-identification/sample_submission.csv')\n",
    "label.head()\n",
    "print(label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['boston_bull', 'dingo', 'pekinese', 'bluetick', 'golden_retriever',\n",
       "       'bedlington_terrier', 'borzoi', 'basenji', 'scottish_deerhound',\n",
       "       'shetland_sheepdog', 'walker_hound', 'maltese_dog',\n",
       "       'norfolk_terrier', 'african_hunting_dog',\n",
       "       'wire-haired_fox_terrier', 'redbone', 'lakeland_terrier', 'boxer',\n",
       "       'doberman', 'otterhound', 'standard_schnauzer',\n",
       "       'irish_water_spaniel', 'black-and-tan_coonhound', 'cairn',\n",
       "       'affenpinscher', 'labrador_retriever', 'ibizan_hound',\n",
       "       'english_setter', 'weimaraner', 'giant_schnauzer', 'groenendael',\n",
       "       'dhole', 'toy_poodle', 'border_terrier', 'tibetan_terrier',\n",
       "       'norwegian_elkhound', 'shih-tzu', 'irish_terrier', 'kuvasz',\n",
       "       'german_shepherd', 'greater_swiss_mountain_dog', 'basset',\n",
       "       'australian_terrier', 'schipperke', 'rhodesian_ridgeback',\n",
       "       'irish_setter', 'appenzeller', 'bloodhound', 'samoyed',\n",
       "       'miniature_schnauzer', 'brittany_spaniel', 'kelpie', 'papillon',\n",
       "       'border_collie', 'entlebucher', 'collie', 'malamute',\n",
       "       'welsh_springer_spaniel', 'chihuahua', 'saluki', 'pug', 'malinois',\n",
       "       'komondor', 'airedale', 'leonberg', 'mexican_hairless',\n",
       "       'bull_mastiff', 'bernese_mountain_dog',\n",
       "       'american_staffordshire_terrier', 'lhasa', 'cardigan',\n",
       "       'italian_greyhound', 'clumber', 'scotch_terrier', 'afghan_hound',\n",
       "       'old_english_sheepdog', 'saint_bernard', 'miniature_pinscher',\n",
       "       'eskimo_dog', 'irish_wolfhound', 'brabancon_griffon',\n",
       "       'toy_terrier', 'chow', 'flat-coated_retriever', 'norwich_terrier',\n",
       "       'soft-coated_wheaten_terrier', 'staffordshire_bullterrier',\n",
       "       'english_foxhound', 'gordon_setter', 'siberian_husky',\n",
       "       'newfoundland', 'briard', 'chesapeake_bay_retriever',\n",
       "       'dandie_dinmont', 'great_pyrenees', 'beagle', 'vizsla',\n",
       "       'west_highland_white_terrier', 'kerry_blue_terrier', 'whippet',\n",
       "       'sealyham_terrier', 'standard_poodle', 'keeshond',\n",
       "       'japanese_spaniel', 'miniature_poodle', 'pomeranian',\n",
       "       'curly-coated_retriever', 'yorkshire_terrier', 'pembroke',\n",
       "       'great_dane', 'blenheim_spaniel', 'silky_terrier',\n",
       "       'sussex_spaniel', 'german_short-haired_pointer', 'french_bulldog',\n",
       "       'bouvier_des_flandres', 'tibetan_mastiff', 'english_springer',\n",
       "       'cocker_spaniel', 'rottweiler'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label['breed'].value_counts().index\n",
    "print(len(label['breed'].unique()))\n",
    "label['breed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id             breed  \\\n",
      "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull   \n",
      "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo   \n",
      "2  001cdf01b096e06d78e9e5112d419397          pekinese   \n",
      "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick   \n",
      "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever   \n",
      "\n",
      "                                             imgpath  \n",
      "0  C:/dev/dog-breed-identification/train/000bec18...  \n",
      "1  C:/dev/dog-breed-identification/train/001513df...  \n",
      "2  C:/dev/dog-breed-identification/train/001cdf01...  \n",
      "3  C:/dev/dog-breed-identification/train/00214f31...  \n",
      "4  C:/dev/dog-breed-identification/train/0021f9ce...  \n"
     ]
    }
   ],
   "source": [
    "filePath = 'C:/dev/dog-breed-identification/train/'\n",
    "f = lambda x: filePath + x + '.jpg'\n",
    "\n",
    "label['imgpath'] = label['id'].apply(f)\n",
    "label.head()\n",
    "print(label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array,load_img,ImageDataGenerator\n",
    "img = load_img('C:/dev/dog-breed-identification/train/e7af8f590b4fbdca0779f5e606ef91a1.jpg', target_size = (100, 100))\n",
    "img = img_to_array(img)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "ff = lambda x: img_to_array(load_img(x , target_size = (10, 10)))\n",
    "label['imgArray'] = label['imgpath'].apply(ff)\n",
    "label['imgArray'][0].shape\n",
    "print(label['imgArray'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= label['imgArray'].values / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19 37 85 ...  3 75 28]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "a = le.fit_transform(label['breed'])\n",
    "print(a)\n",
    "Y_train = np_utils.to_categorical(a)\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size=0.2, random_state = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               3277056   \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 3,401,144\n",
      "Trainable params: 3,401,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# 컨볼루션 신경망의 설정\n",
    "# model = Sequential()\n",
    "model = tensorflow.keras.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))#과적합을 막기위해 날려버림\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))#과적합을 막기위해 날려버림\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))#과적합을 막기위해 날려버림\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_24_input to have 4 dimensions, but got array with shape (10222, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-ace51c0b0bf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m history = model.fit(X_train, Y_train, validation_data=(x_valid, y_valid),\n\u001b[0;32m     18\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     callbacks=[early_stopping_callback,checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         shuffle=shuffle)\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2651\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2653\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    374\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_24_input to have 4 dimensions, but got array with shape (10222, 1)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 모델 최적화 설정\n",
    "MODEL_DIR = 'C:/dev/dog-breed-identification/model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath=\"C:/dev/dog-breed-identification/model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath,\n",
    "                               monitor='val_loss', verbose=1,\n",
    "                               save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "\n",
    "# 모델의 실행\n",
    "history = model.fit(X_train, Y_train, validation_data=(x_valid, y_valid),\n",
    "                    epochs=30, batch_size=200, verbose=0,\n",
    "                    callbacks=[early_stopping_callback,checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-93bdd8d164e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 테스트 정확도 출력\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n Test Accuracy: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 테스트 셋의 오차\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_vloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# 테스트 정확도 출력\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "\n",
    "# 테스트 셋의 오차\n",
    "y_vloss = history.history['val_loss']\n",
    "\n",
    "# 학습셋의 오차\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "# 그래프로 표현\n",
    "x_len = numpy.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label='Testset_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label='Trainset_loss')\n",
    "\n",
    "# 그래프에 그리드를 주고 레이블을 표시\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
